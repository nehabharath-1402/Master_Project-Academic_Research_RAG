METADATA: {'document_id': 'Multilingual_RAG_research_paper', 'section_name': 'to conduct multilingual eval- uations using the SQUAD evaluation script and 3-gram character level. 4 Results & Discusssions The empirical results across different languages on MKQA, MLQA and XOR TyDi QA are reported in Figure 2. Overall, the experiments confirm that extending the retrieval scope to multilingual contexts (MultiRAG) improves the RAG-based pipelines, outperforming language-specific mono- lingual RAG (monoRAG) and naïve approaches 4used via Google Translate API python package 5To', 'chunk_id': 41}

to conduct multilingual eval- uations using the SQUAD evaluation script and 3-gram character level. 4 Results & Discusssions The empirical results across different languages on MKQA, MLQA and XOR TyDi QA are reported in Figure 2. Overall, the experiments confirm that extending the retrieval scope to multilingual contexts (MultiRAG) improves the RAG-based pipelines, outperforming language-specific mono- lingual RAG (monoRAG) and naïve approaches 4used via Google Translate API python package 5To