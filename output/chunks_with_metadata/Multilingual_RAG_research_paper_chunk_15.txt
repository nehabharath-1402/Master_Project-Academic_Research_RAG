METADATA: {'document_id': 'Multilingual_RAG_research_paper', 'section_name': 'question-answering tasks properly constructed for multilingual eval- uation as they best represent multilingual open- ended question-answering tasks (Longpre et al., 2021; Chirkova et al., 2024). Then, we employed different LLMs, chosen for proficiency in RAG tasks and multilingual performances, to investi- gate their capabilities in leveraging multilingual retrieved knowledge. The main contributions of our paper are: • We explore RAG beyond English by showing the benefits derived from', 'chunk_id': 15}

question-answering tasks properly constructed for multilingual eval- uation as they best represent multilingual open- ended question-answering tasks (Longpre et al., 2021; Chirkova et al., 2024). Then, we employed different LLMs, chosen for proficiency in RAG tasks and multilingual performances, to investi- gate their capabilities in leveraging multilingual retrieved knowledge. The main contributions of our paper are: • We explore RAG beyond English by showing the benefits derived from