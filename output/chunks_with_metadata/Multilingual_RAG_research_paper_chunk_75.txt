METADATA: {'document_id': 'Multilingual_RAG_research_paper', 'section_name': 'to scenarios where retrieved documents may not be delivered in the most optimal order. 6 Related Work Previous research investigated the advantages of augmenting large language models (LLMs) through retrieved knowledge, a technique known as Retrieval-augmented Generative (RAG) (Lewis et al., 2020b). Many efforts have concentrated on exploring techniques to improve RAG by operating in-context (Menick et al., 2022), tuning (Gao et al., 2023), or intervening on retrievers (Sawarkar et al., 2024).', 'chunk_id': 75}

to scenarios where retrieved documents may not be delivered in the most optimal order. 6 Related Work Previous research investigated the advantages of augmenting large language models (LLMs) through retrieved knowledge, a technique known as Retrieval-augmented Generative (RAG) (Lewis et al., 2020b). Many efforts have concentrated on exploring techniques to improve RAG by operating in-context (Menick et al., 2022), tuning (Gao et al., 2023), or intervening on retrievers (Sawarkar et al., 2024).